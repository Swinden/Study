# 分类算法 - 随机森林

[分类算法 - 随机森林 (tutorialspoint.com)](https://www.tutorialspoint.com/machine_learning_with_python/classification_algorithms_random_forest.htm#)

[[Python+sklearn\] 计算混淆矩阵 confusion_matrix()函数_Harry嗷的博客-CSDN博客_python混淆矩阵计算](https://blog.csdn.net/qq_41683065/article/details/99776506)

[4.4.2分类模型评判指标（一） - 混淆矩阵(Confusion Matrix)_进击的橘子猫的博客-CSDN博客_混淆矩阵](https://blog.csdn.net/Orange_Spotty_Cat/article/details/80520839)

[python机器学习classification_report()函数 输出模型评估报告_侯小啾的博客-CSDN博客_classification_report函数](https://blog.csdn.net/weixin_48964486/article/details/122881350#:~:text=SnippetTab)

[机器学习classification_report方法及precision精确率和recall召回率 说明 - 178mz - 博客园 (cnblogs.com)](https://www.cnblogs.com/178mz/p/8558435.html#:~:text=classification_report简介,sklearn中的classification_report函数用于显示主要分类指标的文本报告．在报告中显示每个类的精确度，召回率，F1值等信息。)

[Python sklearn.metrics.accuracy_score用法及代码示例 - 纯净天空 (vimsky.com)](https://vimsky.com/examples/usage/python-sklearn.metrics.accuracy_score-sk.html)

## 介绍

​		随机森林是一种监督学习算法，用于分类和回归。但是，它主要用于分类问题。众所周知，森林是由树木组成的，更多的树木意味着更强大的森林。同样，随机森林算法在数据样本上创建决策树，然后从每个样本中获取预测，最后通过投票选择最佳解决方案。它是一种集成方法，比单个决策树更好，因为它通过平均结果来减少过度拟合。

## 随机森林算法的工作原理

​		我们可以借助以下步骤来理解随机森林算法的工作原理 -

* **步骤1** - 首先，从从给定数据集中选择随机样本开始。
* **步骤 2** − 接下来，此算法将为每个样本构造一个决策树。然后，它将从每个决策树中获取预测结果。
* **步骤 3** − 在此步骤中，将对每个预测结果执行投票。
* **步骤 4** − 最后，选择投票最多的预测结果作为最终预测结果。



下图将说明其工作 -

![测试装置](https://www.tutorialspoint.com/machine_learning_with_python/images/test_set.jpg)

## 在 Python 中实现

首先，从导入必要的Python包开始 -

```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
```

接下来，从其 Web 链接下载虹膜数据集，如下所示 -

```python
path = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
```

接下来，我们需要为数据集分配列名，如下所示 -

```python
headernames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']
```

现在，我们需要将数据集读取到 pandas 数据帧，如下所示 -

```python
dataset = pd.read_csv(path, names=headernames)
dataset.head()
```

|      | 萼片长度 | 萼片宽度 | 花瓣长度 | 花瓣宽度 |   类   |
| :--: | :------: | :------: | :------: | :------: | :----: |
|  0   |   5.1    |   3.5    |   1.4    |   0.2    | 鸢尾花 |
|  1   |   4.9    |   3.0    |   1.4    |   0.2    | 鸢尾花 |
|  2   |   4.7    |   3.2    |   1.3    |   0.2    | 鸢尾花 |
|  3   |   4.6    |   3.1    |   1.5    |   0.2    | 鸢尾花 |
|  4   |   5.0    |   3.6    |   1.4    |   0.2    | 鸢尾花 |

数据预处理将在以下脚本行的帮助下完成 -

```python
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 4].values
```

接下来，我们将数据分为训练和测试拆分。以下代码将数据集拆分为 70% 的训练数据和 30% 的测试数据 −

```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)
```

接下来，在sklearn的RandomForestClassifier类的帮助下训练模型，如下所示 -

```python
from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators=50)
classifier.fit(X_train, y_train)
```

最后，我们需要做出预测。它可以在以下脚本的帮助下完成 -

```python
y_pred = classifier.predict(X_test)
```

接下来，按如下方式打印结果 −

```python
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
result = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(result)
result1 = classification_report(y_test, y_pred)
print("Classification Report:",)
print (result1)
result2 = accuracy_score(y_test,y_pred)
print("Accuracy:",result2)
```

### 输出

```python
Confusion Matrix:
[
[14 0 0]
[ 0 18 1]
[ 0 0 12]
]
Classification Report:
precision recall f1-score support
Iris-setosa 1.00 1.00 1.00 14
Iris-versicolor 1.00 0.95 0.97 19
Iris-virginica 0.92 1.00 0.96 12
micro avg 0.98 0.98 0.98 45
macro avg 0.97 0.98 0.98 45
weighted avg 0.98 0.98 0.98 45

Accuracy: 0.9777777777777777
```

## 随机森林的利弊

### 优点

以下是随机森林算法的优点 −

- 它通过平均或组合不同决策树的结果来克服过拟合的问题。
- 随机森林比单个决策树更适合大量数据项。
- 随机森林的方差小于单个决策树。
- 随机森林非常灵活，具有非常高的准确性。
- 在随机林算法中不需要缩放数据。即使在提供数据而不缩放后，它也能保持良好的准确性。
- 在随机林算法中不需要缩放数据。即使在提供数据而不缩放后，它也能保持良好的准确性。

### 缺点

以下是随机森林算法的缺点 -

- 复杂性是随机森林算法的主要缺点。
- 随机森林的构建比决策树更难，更耗时。
- 实现随机森林算法需要更多的计算资源。
- 当我们有大量决策树时，它就不那么直观了。
- 与其他算法相比，使用随机森林的预测过程非常耗时。